{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INTRO\n",
        "- Goal of this notebook is to explore Attention mechanism using generated numerical dataset.\n",
        "- Dataset contains 1D vectors and task of the model is to 'predict' minimum value of the input vector\n",
        "- Attention exploration: attention score might be maximum for index with minimum value in the input vector\n",
        "\n",
        "\n",
        "- Based on:\n",
        "  - https://github.com/thomlake/pytorch-attention/tree/master\n",
        "  - https://colab.research.google.com/drive/1NwwPKYlyOIxeRI1BBUMZ-uFIApyZxARy?usp=sharing#scrollTo=3SqrOPZBKR0r\n",
        "\n",
        "  Please share feedback with: @piotrekgrl"
      ],
      "metadata": {
        "id": "6B3iiBnLBv7M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D2Du6k-x7HHk"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih4OZrUZ7Mfp",
        "outputId": "11e31885-b109-49f2-bcaa-b72fa574330c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a27a8a8ae30>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET"
      ],
      "metadata": {
        "id": "V0Lf9cfl_pgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY = np.array([0.42], dtype=np.float32) # static query for my task - we want to compute minimum from a given array"
      ],
      "metadata": {
        "id": "lEpCYMPK7PWZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIM = 1  # input array dimension"
      ],
      "metadata": {
        "id": "wB3htiI37dX5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(object):\n",
        "    def __init__(self, query, dim):\n",
        "        self.query = query\n",
        "        self.dim = dim\n",
        "\n",
        "    def create_minibatches(self, n, m, length):\n",
        "        minibatches = []\n",
        "        for _ in range(n):\n",
        "            context = np.random.normal(0, 1, (m, length, self.dim)).astype(np.float32)\n",
        "            target_indices = np.argmin(context, axis=1).squeeze()\n",
        "            target = context[np.arange(m), target_indices][:, None]\n",
        "            query = np.tile(self.query, (m, 1, 1))\n",
        "\n",
        "            query = torch.tensor(query)\n",
        "            context = torch.tensor(context)\n",
        "            target = torch.tensor(target)\n",
        "            minibatches.append((query, context, target, target_indices))\n",
        "        return minibatches"
      ],
      "metadata": {
        "id": "RVxxAcfQ7Nk4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "batch_size = 8\n",
        "n_train, n_valid = 200, 100\n",
        "length = 16"
      ],
      "metadata": {
        "id": "QonPUwvN7m5_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Data(QUERY, DATA_DIM)"
      ],
      "metadata": {
        "id": "hSVH_f127uRa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data\n",
        "train_batches = data.create_minibatches(n_train, batch_size, length)\n",
        "valid_batches = data.create_minibatches(n_valid, batch_size, length)"
      ],
      "metadata": {
        "id": "6A2dUT1K7qVC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single data point overview"
      ],
      "metadata": {
        "id": "quMaLVj-_RKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# QUERY (STATIC)\n",
        "train_batches[0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1SAIhXP-8An",
        "outputId": "e875925c-46a6-4eca-f729-9be05084b2b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4200]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONTEXT\n",
        "train_batches[0][1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_dd9qbS_E1u",
        "outputId": "96d7f527-e357-437e-9e89-ed13d9cddecb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4967],\n",
              "        [-0.1383],\n",
              "        [ 0.6477],\n",
              "        [ 1.5230],\n",
              "        [-0.2342],\n",
              "        [-0.2341],\n",
              "        [ 1.5792],\n",
              "        [ 0.7674],\n",
              "        [-0.4695],\n",
              "        [ 0.5426],\n",
              "        [-0.4634],\n",
              "        [-0.4657],\n",
              "        [ 0.2420],\n",
              "        [-1.9133],\n",
              "        [-1.7249],\n",
              "        [-0.5623]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TARGET (min(CONTEXT))\n",
        "train_batches[0][2][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5qJ7wpo_Hvu",
        "outputId": "2b4936f8-0c33-4926-8f8f-1934d388dbff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.9133]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TARGET INDEX (argmin(CONTEXT))\n",
        "train_batches[0][3][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTmAuUcD_Jee",
        "outputId": "22c25835-f159-4a50-b9de-7c2b1ddaa10b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ATTENTION"
      ],
      "metadata": {
        "id": "HIw2-olU_lXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleAttentionNet(nn.Module):\n",
        "    def __init__(self, data_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Q Linear Layer\n",
        "        self.W_q = nn.Linear(data_dim, hidden_dim)\n",
        "\n",
        "        # K Linear Layer\n",
        "        self.W_k = nn.Linear(data_dim, hidden_dim)\n",
        "        self.d_k = hidden_dim\n",
        "\n",
        "        # V Linear Layer\n",
        "        self.W_v = nn.Linear(data_dim, hidden_dim)\n",
        "\n",
        "        # Output Linear Layer\n",
        "        self.W_o = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, q, x, return_weight=False):\n",
        "        # Compute Q, K, V representations\n",
        "        Q = self.W_q(q.squeeze(-1)).unsqueeze(1)\n",
        "        K = self.W_k(x)\n",
        "        V = self.W_v(x)\n",
        "\n",
        "    # source: MultiHeadAttention.scaled_dot_product_attention()\n",
        "    # https://colab.research.google.com/drive/1NwwPKYlyOIxeRI1BBUMZ-uFIApyZxARy?usp=sharing#scrollTo=3SqrOPZBKR0r\n",
        "    # START\n",
        "        # Compute attention scores and weights\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "    # END\n",
        "\n",
        "        # Final output\n",
        "        output = self.W_o(output)\n",
        "\n",
        "        # Return output and optionally attn_weights\n",
        "        if return_weight:\n",
        "            return output, attn_probs.squeeze(1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "nySqACcq-PEn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, optimizer, and loss function\n",
        "net = SimpleAttentionNet(data_dim=DATA_DIM, hidden_dim=5)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "mse_loss = nn.MSELoss()"
      ],
      "metadata": {
        "id": "O1L89kHi8WnZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "gX0tU2cs8bdC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_parameters(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axcSYG438dpZ",
        "outputId": "b445756e-0848-4a67-b416-acae6b35bb05"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    for query, context, target, _ in train_batches:\n",
        "        optimizer.zero_grad()\n",
        "        output = net(query, context)\n",
        "        loss = mse_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {train_loss / len(train_batches):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BeCDD_n8e0S",
        "outputId": "68f8efa8-7ddf-4069-c148-9449083b3380"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.9570\n",
            "Epoch 2, Loss: 0.5266\n",
            "Epoch 3, Loss: 0.4744\n",
            "Epoch 4, Loss: 0.4431\n",
            "Epoch 5, Loss: 0.4156\n",
            "Epoch 6, Loss: 0.3920\n",
            "Epoch 7, Loss: 0.3720\n",
            "Epoch 8, Loss: 0.3554\n",
            "Epoch 9, Loss: 0.3416\n",
            "Epoch 10, Loss: 0.3304\n",
            "Epoch 11, Loss: 0.3217\n",
            "Epoch 12, Loss: 0.3152\n",
            "Epoch 13, Loss: 0.3108\n",
            "Epoch 14, Loss: 0.3079\n",
            "Epoch 15, Loss: 0.3062\n",
            "Epoch 16, Loss: 0.3053\n",
            "Epoch 17, Loss: 0.3048\n",
            "Epoch 18, Loss: 0.3045\n",
            "Epoch 19, Loss: 0.3044\n",
            "Epoch 20, Loss: 0.3043\n",
            "Epoch 21, Loss: 0.3041\n",
            "Epoch 22, Loss: 0.3040\n",
            "Epoch 23, Loss: 0.3038\n",
            "Epoch 24, Loss: 0.3035\n",
            "Epoch 25, Loss: 0.3030\n",
            "Epoch 26, Loss: 0.3020\n",
            "Epoch 27, Loss: 0.2994\n",
            "Epoch 28, Loss: 0.2892\n",
            "Epoch 29, Loss: 0.2297\n",
            "Epoch 30, Loss: 0.0943\n",
            "Epoch 31, Loss: 0.0300\n",
            "Epoch 32, Loss: 0.0158\n",
            "Epoch 33, Loss: 0.0116\n",
            "Epoch 34, Loss: 0.0093\n",
            "Epoch 35, Loss: 0.0077\n",
            "Epoch 36, Loss: 0.0066\n",
            "Epoch 37, Loss: 0.0057\n",
            "Epoch 38, Loss: 0.0050\n",
            "Epoch 39, Loss: 0.0045\n",
            "Epoch 40, Loss: 0.0040\n",
            "Epoch 41, Loss: 0.0036\n",
            "Epoch 42, Loss: 0.0033\n",
            "Epoch 43, Loss: 0.0030\n",
            "Epoch 44, Loss: 0.0028\n",
            "Epoch 45, Loss: 0.0026\n",
            "Epoch 46, Loss: 0.0024\n",
            "Epoch 47, Loss: 0.0022\n",
            "Epoch 48, Loss: 0.0021\n",
            "Epoch 49, Loss: 0.0019\n",
            "Epoch 50, Loss: 0.0018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "query, context, target, target_indices = valid_batches[0]\n",
        "\n",
        "with torch.no_grad():\n",
        "    output, weight = net(query, context, return_weight=True)"
      ],
      "metadata": {
        "id": "oKDV0V0S8pmC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmin(context[2].numpy()) # index of minimum element in the input data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z45W3nFl85Wp",
        "outputId": "7baf84f6-1e75-457b-8234-157422e495ea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(weight[2].numpy()) # maximum attention weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARz2vo6H9M_Z",
        "outputId": "85fdf3cb-5e7d-4f3c-b213-0d1da5cc2eca"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[2] # predicted value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWOnaGxbA9n9",
        "outputId": "02258410-0d1e-4f31-ddf2-7ccfb0a7c012"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.6838]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target[2] # predicted target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAaijvBjA-qM",
        "outputId": "1a005a38-24b2-437a-cc4f-994cd641fbd6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.7276]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Looks good?"
      ],
      "metadata": {
        "id": "bmL6bU-1DCua"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}